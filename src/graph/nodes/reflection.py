"""
Reflection Node
Generation'Ä±n kalitesini kontrol eder ve gerekirse regenerate eder
"""
from src.graph.state import GraphState
from src.graph.nodes.graders import HallucinationGrader
from src.services.llm_services import LLMService
from langchain_core.prompts import ChatPromptTemplate

class ReflectionNode:
    """
    Level 1 Reflection: Sadece Hallucination Check
    
    Generation'Ä± kontrol eder:
    - Hallucination var mÄ±? â†’ Regenerate
    - Hallucination yok mu? â†’ Approve
    """
    
    def __init__(self):
        self.hallucination_grader = HallucinationGrader()
        self.llm_service = LLMService()
        self.llm = self.llm_service.get_llm()
        
        # Regeneration prompt (daha dikkatli)
        self.regenerate_prompt = ChatPromptTemplate.from_messages([
            ("system", """Sen HaliÃ§ Ãœniversitesi GiriÅŸimcilik ve Pazarlama KulÃ¼bÃ¼ asistanÄ±sÄ±n.

            Ã–NCEKÄ° CEVABINDA HATA VARMIÅ! LÃ¼tfen daha DÄ°KKATLÄ° ol.

            KURALLAR:
            1. SADECE verilen CONTEXT'teki bilgileri kullan
            2. Tarih, saat, isim gibi bilgileri TAM OLARAK yaz
            3. CONTEXT'te OLMAYAN bilgi verme
            4. Emin deÄŸilsen "Bu konuda detaylÄ± bilgi bulamadÄ±m" de

            CONTEXT:
            {context}
            """),
                        ("human", "{question}")
                    ])
    
    def __call__(self, state: GraphState) -> GraphState:
        """
        Reflection logic
        
        Args:
            state: Mevcut graph state (generation ile)
            
        Returns:
            Updated state (onaylanmÄ±ÅŸ veya regenerate edilmiÅŸ)
        """
        question = state["question"]
        generation = state["generation"]
        documents = state["documents"]
        iterations = state.get("iterations", 0)
        max_iterations = 2  # Max 2 regeneration
        
        print(f"\n   ğŸ” Reflection Node: Checking quality (iteration {iterations})...")
        
        # Hallucination check
        hallucination_result = self.hallucination_grader.grade(
            generation=generation,
            documents=documents
        )
        
        print(f"   ğŸ“Š Hallucination Check: {hallucination_result.binary_score}")
        print(f"   ğŸ’­ Reasoning: {hallucination_result.reasoning}")
        
        # EÄŸer grounded ise (hallucination yok)
        if hallucination_result.binary_score:
            print("   âœ… Quality check PASSED! Cevap documents'a sadÄ±k.")
            return {
                **state,
                "iterations": iterations + 1
            }
        
        # Hallucination var!
        print("   âŒ Quality check FAILED! Hallucination detected!")
        
        # Max iteration aÅŸÄ±ldÄ± mÄ±?
        if iterations >= max_iterations:
            print(f"   âš ï¸  Max iteration ({max_iterations}) reached. Using best attempt.")
            return {
                **state,
                "generation": generation + "\n\n(Not: Bu bilgi dÃ¶kÃ¼manlarÄ±mÄ±zda tam olarak bulunamadÄ±. LÃ¼tfen kulÃ¼ple direkt iletiÅŸime geÃ§in.)",
                "iterations": iterations + 1
            }
        
        # Regenerate
        print("   ğŸ”„ Regenerating with more careful prompt...")
        
        # Context hazÄ±rla
        context = "\n\n---\n\n".join([
            f"[Kaynak: {doc.metadata.get('source', 'Unknown')}]\n{doc.page_content}"
            for doc in documents
        ])
        
        # Regenerate
        chain = self.regenerate_prompt | self.llm
        new_response = chain.invoke({
            "context": context,
            "question": question
        })
        
        print(f"   âœ… Regenerated ({len(new_response.content)} characters)")
        
        return {
            **state,
            "generation": new_response.content,
            "iterations": iterations + 1
        }