"""
RAG Nodes
Retrieve ve Generate node'larÄ±
"""
from langchain_core.prompts import ChatPromptTemplate
from src.graph.state import GraphState
from src.services.vectorstore_service import VectorStoreService
from src.services.llm_services import LLMService
from src.services.memory_service import MemoryService

class RetrieveNode:
    """Pinecone'dan dÃ¶kÃ¼man getiren node"""
    
    def __init__(self):
        self.vectorstore_service = VectorStoreService()
        self.memory_service = MemoryService()
    
    def __call__(self, state: GraphState) -> GraphState:
        """
        Pinecone'dan dÃ¶kÃ¼man retrieval
        
        Args:
            state: Mevcut graph state
            
        Returns:
            Updated state with documents
        """
        session_id = state.get("session_id", "default")
        question = state["question"]
        
        # Memory'den context al
        last_topic = self.memory_service.get_last_topic(session_id)
        
        # Query'yi geniÅŸlet (eÄŸer takip sorusu ise)
        # "detaylandÄ±r", "aÃ§Ä±kla", "anlat" gibi kelimeler topic ile birleÅŸtir
        expanded_query = question
        
        if last_topic and any(word in question.lower() for word in [
            "detay", "aÃ§Ä±kla", "anlat", "geniÅŸlet", "daha fazla", 
            "kimler", "ne zaman", "nerede", "nasÄ±l", "kaÃ§"
        ]):
            # Topic'i query'e ekle
            expanded_query = f"{last_topic} {question}"
            print(f"\n   ðŸ” Query expanded: '{question}' â†’ '{expanded_query}'")
        
        # Retrieve documents
        documents = self.vectorstore_service.retrieve_documents(
            query=expanded_query
        )
        
        return {
            **state,
            "documents": documents
        }

class GenerateRAGNode:
    """RAG ile cevap Ã¼reten node"""
    
    def __init__(self):
        self.llm_service = LLMService()
        self.llm = self.llm_service.get_llm()
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """Sen HaliÃ§ Ãœniversitesi GiriÅŸimcilik ve Pazarlama KulÃ¼bÃ¼ asistanÄ±sÄ±n.

CONTEXT'teki dÃ¶kÃ¼manlarÄ± kullanarak soruyu yanÄ±tla.

KURALLAR:
1. Sadece CONTEXT'teki bilgileri kullan
2. ETKÄ°NLÄ°K sorularÄ±nda MUTLAKA spesifik isimlerini belirt (FESTUP, Social Media Talks, DigitalMAG, HUGÄ°P Akademi vb.)
3. "Etkinlikler", "festivaller", "konferanslar" gibi genel ifadeler YERÄ°NE etkinlik isimleri say
4. Ã–rnek: "FESTUP, Social Media Talks ve DigitalMAG gibi etkinlikler dÃ¼zenliyoruz"
5. EÄŸer bilgi yoksa "Bu konuda dÃ¶kÃ¼manlarÄ±mda detaylÄ± bilgi bulamadÄ±m" de
6. KÄ±sa, Ã¶z ve samimi ol
7. Kaynak belirtmeye gerek yok (otomatik gÃ¶sterilecek)
8. TÃ¼rkÃ§e sorulara TÃ¼rkÃ§e, Ä°ngilizce sorulara Ä°ngilizce cevap ver

Ã–NEMLÄ°: Context'te etkinlik/proje isimleri gÃ¶rÃ¼yorsan, bunlarÄ± cevabÄ±nda MUTLAKA kullan!

CONTEXT:
{context}
"""),
            ("human", "{question}")
        ])
    
    def __call__(self, state: GraphState) -> GraphState:
        """
        RAG generation
        
        Args:
            state: Mevcut graph state (documents ile)
            
        Returns:
            Updated state with generation
        """
        # Context hazÄ±rla
        context = "\n\n---\n\n".join([
            f"[Kaynak: {doc.metadata.get('source', 'Unknown')}]\n{doc.page_content}"
            for doc in state["documents"]
        ])
        
        # Generate
        chain = self.prompt | self.llm
        response = chain.invoke({
            "context": context,
            "question": state["question"]
        })
        
        return {
            **state,
            "generation": response.content
        }